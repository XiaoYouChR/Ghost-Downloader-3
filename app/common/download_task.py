import asyncio
import struct
import sys
import time
from asyncio import Task
from pathlib import Path
from threading import Thread

import aiofiles
import httpx
from PySide6.QtCore import QThread, Signal
from loguru import logger

from app.common.config import cfg
from app.common.methods import getProxy, getReadableSize, getLinkInfo

Headers = {
    "accept-encoding": "deflate, br, gzip",
    "accept-language": "zh-CN,zh;q=0.9",
    "cookie": "down_ip=1",
    "sec-fetch-dest": "document",
    "sec-fetch-mode": "navigate",
    "sec-fetch-site": "none",
    "sec-fetch-user": "?1",
    "upgrade-insecure-requests": "1",
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 Edg/112.0.1722.64"}

class DownloadWorker:
    """åªèƒ½å‡ºå–åŠ³åŠ¨åŠ›çš„æœ€åº•å±‚å·¥ä½œè€…"""

    def __init__(self, start, process, end, client: httpx.AsyncClient):
        self.startPos = start
        self.process = process
        self.endPos = end

        self.client = client


class DownloadTask(QThread):
    """TaskManager"""

    taskInited = Signal()  # çº¿ç¨‹åˆå§‹åŒ–æˆåŠŸ
    # processChange = Signal(str)  # ç›®å‰è¿›åº¦ ä¸”å› ä¸ºC++ intæœ€å¤§å€¼ä»…æ”¯æŒåˆ°2^31 PyQtåˆæ²¡æœ‰Qintç±» æ•…åªèƒ½ä½¿ç”¨strä»£æ›¿
    workerInfoChanged = Signal(list)  # ç›®å‰è¿›åº¦ v3.2ç‰ˆæœ¬å¼•è¿›äº†åˆ†æ®µå¼è¿›åº¦æ¡
    speedChanged = Signal(int)  # å¹³å‡é€Ÿåº¦ å› ä¸º autoSpeedUp åŠŸèƒ½éœ€è¦å®æ—¶è®¡ç®—å¹³å‡é€Ÿåº¦ v3.4.4 èµ·ç§»å…¥åç«¯è®¡ç®—é€Ÿåº¦, æ¯ç§’é€Ÿåº¦å¯èƒ½è¶…è¿‡ 2^31 Bytes å—ï¼Ÿ
    taskFinished = Signal()  # å†…ç½®ä¿¡å·çš„ä¸å¥½ç”¨
    gotWrong = Signal(str)  # ğŸ˜­ æˆ‘å‡ºé—®é¢˜äº†

    def __init__(self, url, preTaskNum: int = 8, filePath=None, fileName=None, autoSpeedUp=cfg.autoSpeedUp.value, parent=None):
        super().__init__(parent)

        self.aioLock = asyncio.Lock()
        self.process = 0
        self.url = url
        self.fileName = fileName
        self.filePath = filePath
        self.preBlockNum = preTaskNum
        self.autoSpeedUp = autoSpeedUp

        self.workers: list[DownloadWorker] = []
        self.tasks: list[Task] = []
        self.historySpeed = [0] * 10  # å†å²é€Ÿåº¦ 10 ç§’å†…çš„å¹³å‡é€Ÿåº¦

        self.client = httpx.AsyncClient(headers=Headers, verify=False,
                                        proxy=getProxy(), limits=httpx.Limits(max_connections=256))

        self.__tempThread = Thread(target=self.__getLinkInfo, daemon=True)  # TODO è·å–æ–‡ä»¶åå’Œæ–‡ä»¶å¤§å°çš„çº¿ç¨‹ç­‰ä¿¡æ¯, æš‚æ—¶ä½¿ç”¨çº¿ç¨‹æ–¹å¼
        self.__tempThread.start()

    def __reassignWorker(self):

        # æ‰¾åˆ°å‰©ä½™è¿›åº¦æœ€å¤šçš„çº¿ç¨‹
        maxRemainder = 0
        maxRemainderWorkerProcess = 0
        maxRemainderWorkerEnd = 0
        maxRemainderWorker: DownloadWorker = None

        for i in self.workers:
            if (i.endPos - i.process) > maxRemainder:  # TODO å…¶å®é€»è¾‘æœ‰ä¸€ç‚¹é—®é¢˜, ä½†æ˜¯å½±å“ä¸å¤§
                maxRemainderWorkerProcess = i.process
                maxRemainderWorkerEnd = i.endPos
                maxRemainder = (maxRemainderWorkerEnd - maxRemainderWorkerProcess)
                maxRemainderWorker = i

        if maxRemainderWorker and maxRemainder > cfg.maxReassignSize.value * 1048576:  # è½¬æ¢æˆ MB
            # å¹³å‡åˆ†é…å·¥ä½œé‡
            baseShare = maxRemainder // 2
            remainder = maxRemainder % 2

            maxRemainderWorker.endPos = maxRemainderWorkerProcess + baseShare + remainder  # ç›´æ¥ä¿®æ”¹å¥½åƒä¹Ÿä¸ä¼šæ€ä¹ˆæ ·

            # å®‰é…æ–°çš„å·¥äºº
            s_pos = maxRemainderWorkerProcess + baseShare + remainder + 1

            newWorker = DownloadWorker(s_pos, s_pos, maxRemainderWorkerEnd, self.client)

            newTask = self.loop.create_task(self.__handleWorker(newWorker))

            self.workers.insert(self.workers.index(maxRemainderWorker) + 1, newWorker)
            self.tasks.append(newTask)

            logger.info(
                f"Task{self.fileName} åˆ†é…æ–°çº¿ç¨‹æˆåŠŸ, å‰©ä½™é‡ï¼š{getReadableSize(maxRemainder)}ï¼Œä¿®æ”¹åçš„EndPosï¼š{maxRemainderWorker.endPos}ï¼Œæ–°çº¿ç¨‹ï¼š{newWorker}ï¼Œæ–°çº¿ç¨‹çš„StartPosï¼š{s_pos}")

        else:
            logger.info(
                f"Task{self.fileName} æ¬²åˆ†é…æ–°çº¿ç¨‹å¤±è´¥, å‰©ä½™é‡å°äºæœ€å°åˆ†å—å¤§å°, å‰©ä½™é‡ï¼š{getReadableSize(maxRemainder)}")

    def __clacDivisionalRange(self):
        step = self.fileSize // self.preBlockNum  # æ¯å—å¤§å°
        arr = list(range(0, self.fileSize, step))

        # å¦åˆ™çº¿ç¨‹æ•°å¯èƒ½ä¼šä¸æŒ‰é¢„æœŸåœ°å°‘ä¸€ä¸ª
        if self.fileSize % self.preBlockNum == 0:
            arr.append(self.fileSize)

        step_list = []

        for i in range(len(arr) - 1):  #

            s_pos, e_pos = arr[i], arr[i + 1] - 1
            step_list.append([s_pos, e_pos])

        step_list[-1][-1] = self.fileSize - 1  # ä¿®æ­£

        return step_list

    def __getLinkInfo(self):
        try:
            self.url, self.fileName, self.fileSize = getLinkInfo(self.url, Headers, self.fileName)

            if self.fileSize:
                self.ableToParallelDownload = True
            else:
                self.ableToParallelDownload = False  # TODO å¤„ç†æ— æ³•å¹¶è¡Œä¸‹è½½çš„æƒ…å†µ

            # è·å–æ–‡ä»¶è·¯å¾„
            if not self.filePath and Path(self.filePath).is_dir() == False:
                self.filePath = Path.cwd()

            else:
                self.filePath = Path(self.filePath)
                if not self.filePath.exists():
                    self.filePath.mkdir()

        except Exception as e:  # é‡è¯•ä¹Ÿæ²¡ç”¨
            self.gotWrong.emit(str(e))

    def __loadWorkers(self):
        # å¦‚æœ .ghd æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å¹¶è§£æäºŒè¿›åˆ¶æ•°æ®
        filePath = Path(f"{self.filePath}/{self.fileName}.ghd")
        if filePath.exists():
            try:
                with open(filePath, "rb") as f:
                    while True:
                        data = f.read(24)  # æ¯ä¸ª worker æœ‰ 3 ä¸ª 64 ä½çš„æ— ç¬¦å·æ•´æ•°ï¼Œå…± 24 å­—èŠ‚

                        if not data:
                            break

                        start, process, end = struct.unpack("<QQQ", data)
                        self.workers.append(
                            DownloadWorker(start, process, end, self.client))

            except Exception as e:
                logger.error(f"Failed to load workers: {e}")
                stepList = self.__clacDivisionalRange()

                for i in range(self.preBlockNum):
                    self.workers.append(
                        DownloadWorker(stepList[i][0], stepList[i][0], stepList[i][1], self.client))
        else:
            stepList = self.__clacDivisionalRange()

            for i in range(self.preBlockNum):
                self.workers.append(
                    DownloadWorker(stepList[i][0], stepList[i][0], stepList[i][1], self.client))

    async def __handleWorker(self, worker: DownloadWorker):
        if worker.process < worker.endPos:  # å› ä¸ºå¯èƒ½ä¼šåˆ›å»ºç©ºçº¿ç¨‹
            finished = False
            while not finished:
                try:
                    download_headers = Headers.copy()
                    download_headers["range"] = f"bytes={worker.process}-{worker.endPos}"  # æ·»åŠ èŒƒå›´

                    async with worker.client.stream(url=self.url, headers=download_headers, timeout=30,
                                                    method="GET") as res:
                        async for chunk in res.aiter_bytes(chunk_size=65536):  # aiter_content çš„å•ä½æ˜¯å­—èŠ‚, å³æ¯64Kå†™ä¸€æ¬¡æ–‡ä»¶
                            if worker.endPos <= worker.process:
                                break
                            if chunk:
                                async with self.aioLock:
                                    await self.file.seek(worker.process)
                                    await self.file.write(chunk)
                                    worker.process += 65536

                    if worker.process >= worker.endPos:
                        worker.process = worker.endPos

                    finished = True

                except httpx.HTTPError as e:
                    logger.info(
                        f"Task: {self.fileName}, Thread {worker} is reconnecting to the server, Error: {repr(e)}")

                    self.gotWrong.emit(repr(e))

                    await asyncio.sleep(5)

            worker.process = worker.endPos
        self.__reassignWorker()

    async def __supervisor(self):
        """å®æ—¶ç»Ÿè®¡è¿›åº¦å¹¶å†™å…¥å†å²è®°å½•æ–‡ä»¶"""

        for i in self.workers:
            self.process += (i.process - i.startPos + 1)
            LastProcess = self.process

        if self.autoSpeedUp:
            # åˆå§‹åŒ–å˜é‡
            maxSpeedPerConnect = 1 # é˜²æ­¢é™¤ä»¥0
            additionalTaskNum = len(self.tasks) # æœ€åˆä¸ºè®¡ç®—æ¯ä¸ªçº¿ç¨‹çš„å¹³å‡é€Ÿåº¦
            formerAvgSpeed = 0 # æé€Ÿä¹‹å‰çš„å¹³å‡é€Ÿåº¦
            duringTime = 0 # è®¡ç®—å¹³å‡é€Ÿåº¦çš„æ—¶é—´é—´éš”, ä¸º 10 ç§’

        while not self.process == self.fileSize:

            # è®°å½•æ¯å—ä¿¡æ¯
            await self.ghdFile.seek(0)
            info = []
            self.process = 0

            for i in self.workers:
                info.append({"start": i.startPos, "process": i.process, "end": i.endPos})

                self.process += (i.process - i.startPos + 1)

                # ä¿å­˜ workers ä¿¡æ¯ä¸ºäºŒè¿›åˆ¶æ ¼å¼
                data = struct.pack("<QQQ", i.startPos, i.process, i.endPos)
                await self.ghdFile.write(data)

            await self.ghdFile.flush()
            await self.ghdFile.truncate()

            self.workerInfoChanged.emit(info)

            # è®¡ç®—é€Ÿåº¦
            speed = (self.process - LastProcess)
            # print(f"speed: {speed}, process: {self.process}, LastProcess: {LastProcess}")
            LastProcess = self.process
            self.historySpeed.pop(0)
            self.historySpeed.append(speed)
            avgSpeed = sum(self.historySpeed) / 10

            self.speedChanged.emit(avgSpeed)

            # print(f"avgSpeed: {avgSpeed}, historySpeed: {self.historySpeed}")

            if self.autoSpeedUp:
                if duringTime < 10:
                    duringTime += 1
                else:
                    duringTime = 0

                    speedPerConnect = avgSpeed / len(self.tasks)
                    # print(f"taskNum: {len(self.tasks)}, speedPerConnect: {speedPerConnect}, maxSpeedPerConnect: {maxSpeedPerConnect}")

                    if speedPerConnect > maxSpeedPerConnect:
                        maxSpeedPerConnect = speedPerConnect

                    # if maxSpeedPerConnect <= 1:
                    #     await asyncio.sleep(1)
                    #     continue

                    # logger.debug(f"å½“å‰æ•ˆç‡: {(avgSpeed - formerAvgSpeed) / additionalTaskNum / maxSpeedPerConnect}, speed: {speed}, formerAvgSpeed: {formerAvgSpeed}, additionalTaskNum: {additionalTaskNum}, maxSpeedPerConnect: {maxSpeedPerConnect}")

                    if (avgSpeed - formerAvgSpeed) / additionalTaskNum / maxSpeedPerConnect >= 0.85:
                        #  æ–°å¢åŠ çº¿ç¨‹çš„æ•ˆç‡ >= 0.85 æ—¶ï¼Œæ–°å¢çº¿ç¨‹
                        # logger.debug(f'è‡ªåŠ¨æé€Ÿå¢åŠ æ–°çº¿ç¨‹, å½“å‰æ•ˆç‡: {(avgSpeed - formerAvgSpeed) / additionalTaskNum / maxSpeedPerConnect}')
                        formerAvgSpeed = avgSpeed
                        additionalTaskNum = 4

                        if len(self.tasks)  < 253:
                            for i in range(4):
                                self.__reassignWorker()  # æ–°å¢çº¿ç¨‹


            await asyncio.sleep(1)

    async def __main(self):
        try:
            # æ‰“å¼€ä¸‹è½½æ–‡ä»¶
            self.file = await aiofiles.open(f"{self.filePath}/{self.fileName}", "rb+")

            # å¯åŠ¨ Worker
            for i in self.workers:
                logger.debug(f"Task {self.fileName}, starting the thread {i}...")

                _ = asyncio.create_task(self.__handleWorker(i))

                self.tasks.append(_)

            self.ghdFile = await aiofiles.open(f"{self.filePath}/{self.fileName}.ghd", "wb")
            self.supervisorTask = asyncio.create_task(self.__supervisor())

            # ä»…ä»…éœ€è¦ç­‰å¾… supervisorTask
            try:
                await self.supervisorTask
            except asyncio.CancelledError:
                await self.client.aclose()

            # å…³é—­
            await self.client.aclose()

            await self.file.close()
            await self.ghdFile.close()

            if self.process == self.fileSize:
                # ä¸‹è½½å®Œæˆæ—¶åˆ é™¤å†å²è®°å½•æ–‡ä»¶, é˜²æ­¢æ²¡ä¸‹è½½å®Œæ—¶è¯¯åˆ 
                try:
                    Path(f"{self.filePath}/{self.fileName}.ghd").unlink()

                except Exception as e:
                    logger.error(f"Failed to delete the history file, please delete it manually. Err: {e}")

                logger.info(f"Task {self.fileName} finished!")

                self.taskFinished.emit()

        except Exception as e:
            self.gotWrong.emit(repr(e))

    def stop(self):
        for task in self.tasks:
            task.cancel()

        # å…³é—­
        try:
            self.supervisorTask.cancel()
        finally:

            while not all(task.done() for task in self.tasks):  # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                for task in self.tasks:
                    try:
                        task.cancel()
                    except RuntimeError:
                        pass
                    except Exception as e:
                        raise e

                time.sleep(0.05)

    # @retry(3, 0.1)
    def run(self):
        self.__tempThread.join()

        # æ£€éªŒæ–‡ä»¶åˆæ³•æ€§å¹¶è‡ªåŠ¨é‡å‘½å
        if sys.platform == "win32":
            self.fileName = ''.join([i for i in self.fileName if i not in r'\/:*?"<>|'])  # å»é™¤Windowsç³»ç»Ÿä¸å…è®¸çš„å­—ç¬¦
        if len(self.fileName) > 255:
            self.fileName = self.fileName[:255]

        Path(f"{self.filePath}/{self.fileName}").touch()

        # ä»»åŠ¡åˆå§‹åŒ–å®Œæˆ
        self.taskInited.emit()

        # TODO å‘æ¶ˆæ¯ç»™ä¸»çº¿ç¨‹
        if not self.ableToParallelDownload:
            self.preBlockNum = 1

        # åŠ è½½åˆ†å—
        self.__loadWorkers()

        # ä¸»é€»è¾‘, ä½¿ç”¨äº‹ä»¶å¾ªç¯å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)

        try:
            self.loop.run_until_complete(self.__main())
        except asyncio.CancelledError as e:
            print(e)
        finally:
            self.loop.run_until_complete(self.loop.shutdown_asyncgens())
            self.loop.close()
