import re
import urllib
from email.utils import decode_rfc2231
from pathlib import Path
from time import sleep, time
from urllib.parse import urlparse, parse_qs, unquote

import httpx,aiofiles,asyncio
from PySide6.QtCore import QThread, Signal
from httpx import Client
from loguru import logger

from app.common.config import cfg
from app.common.methods import getProxy, getReadableSize, retry

Headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 Edg/112.0.1722.64"}

urlRe = re.compile(r"^" +
                   "((?:https?|ftp)://)" +
                   "(?:\\S+(?::\\S*)?@)?" +
                   "(?:" +
                   "(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])" +
                   "(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}" +
                   "(\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))" +
                   "|" +
                   "((?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)" +
                   '(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)*' +
                   "(\\.([a-z\\u00a1-\\uffff]{2,}))" +
                   ")" +
                   "(?::\\d{2,5})?" +
                   "(?:/\\S*)?" +
                   "$", re.IGNORECASE)


def getRealUrl(url: str):
    # try:
        response = httpx.head(url=url, headers=Headers, follow_redirects=False, verify=False,
                              proxy=getProxy())

        if response.status_code == 400:  # Bad Requests
            # TODO æŠ¥é”™å¤„ç†
            logger.error("HTTP status code 400, it seems that the url is unavailable")
            return

        while response.status_code == 302:  # å½“302çš„æ—¶å€™
            rs = response.headers["location"]  # è·å–é‡å®šå‘ä¿¡æ¯
            logger.info(f'HTTP status code:302, Headers["Location"] is: {rs}')
            # çœ‹å®ƒè¿”å›çš„æ˜¯ä¸æ˜¯å®Œæ•´çš„URL
            t = urlRe.search(rs)
            if t:  # æ˜¯çš„è¯ç›´æ¥è·³è½¬
                url = rs
            elif not t:  # ä¸æ˜¯åœ¨å‰é¢åŠ ä¸ŠURL
                url = re.findall(r"((?:https?|ftp)://[\s\S]*?)/", url)
                url = url[0] + rs

                logger.info(f"HTTP status code:302, Redirect to {url}")

            response = httpx.head(url=url, headers=Headers, follow_redirects=False, verify=False,
                                  proxy=getProxy())  # å†è®¿é—®ä¸€æ¬¡

        return url

    # TODO æŠ¥é”™å¤„ç†
    # except httpx.ConnectError as err:
    #     logger.error(f"Cannot connect to the Internet! Error: {err}")
    #     return
    # except ValueError as err:
    #     logger.error(f"Cannot connect to the Internet! Error: {err}")
    #     return
    # except httpx.ConnectTimeout as err:
    #     logger.error(f"Cannot connect to the Internet! Error: {err}")
    #     return

class DownloadTask(QThread):
    """ä½œç”¨ç›¸å½“äºåŒ…å·¥å¤´"""

    taskInited = Signal()  # çº¿ç¨‹åˆå§‹åŒ–æˆåŠŸ
    # processChange = Signal(str)  # ç›®å‰è¿›åº¦ ä¸”å› ä¸ºC++ intæœ€å¤§å€¼ä»…æ”¯æŒåˆ°2^31 PyQtåˆæ²¡æœ‰Qintç±» æ•…åªèƒ½ä½¿ç”¨strä»£æ›¿
    workerInfoChange = Signal(list)  # ç›®å‰è¿›åº¦ v3.2ç‰ˆæœ¬å¼•è¿›äº†åˆ†æ®µå¼è¿›åº¦æ¡
    taskFinished = Signal()  # å†…ç½®ä¿¡å·çš„ä¸å¥½ç”¨
    gotWrong = Signal(str)  # ğŸ˜­ æˆ‘å‡ºé—®é¢˜äº†

    def __init__(self, url, maxBlockNum: int = 8, filePath=None, fileName=None, parent=None):
        super().__init__(parent)

        self.process = []
        self.url = url
        self.fileName = fileName
        self.filePath = filePath
        self.maxBlockNum = maxBlockNum
        self.workers: list[DownloadWorker] = []
        self.file_manager = aiofiles.open(f"{filePath}/{fileName}",'w+b')
        self.file_lock = asyncio.Lock()#é”

        self.client = httpx.AsyncClient(headers=Headers, verify=False,
                                   proxy=getProxy())

    def reassignWorker(self):

        # æ‰¾åˆ°å‰©ä½™è¿›åº¦æœ€å¤šçš„çº¿ç¨‹
        maxRemainder = 0
        maxRemainderWorker: DownloadWorker = None

        for i in self.workers:
            if (i.endPos - i.process) > maxRemainder:  # TODO å…¶å®é€»è¾‘æœ‰ä¸€ç‚¹é—®é¢˜, ä½†æ˜¯å½±å“ä¸å¤§ 
                maxRemainderWorkerProcess = i.process
                maxRemainderWorkerEnd = i.endPos
                maxRemainder = (maxRemainderWorkerEnd - maxRemainderWorkerProcess)
                maxRemainderWorker = i

        if maxRemainderWorker and maxRemainder > cfg.maxReassignSize.value * 1048576:
            # å¹³å‡åˆ†é…å·¥ä½œé‡
            baseShare = maxRemainder // 2
            remainder = maxRemainder % 2

            maxRemainderWorker.endPos = maxRemainderWorkerProcess + baseShare + remainder  # ç›´æ¥ä¿®æ”¹å¥½åƒä¹Ÿä¸ä¼šæ€ä¹ˆæ ·

            # å®‰é…æ–°çš„å·¥äºº
            s_pos = maxRemainderWorkerProcess + baseShare + remainder + 1

            _ = DownloadWorker(s_pos, s_pos, maxRemainderWorkerEnd, self)
            asyncio.create_task(_.run())
            self.workers.insert(self.workers.index(maxRemainderWorker) + 1, _)

            logger.info(
                f"Task{self.fileName} åˆ†é…æ–°çº¿ç¨‹æˆåŠŸ, å‰©ä½™é‡ï¼š{getReadableSize(maxRemainder)}ï¼Œä¿®æ”¹åçš„EndPosï¼š{maxRemainderWorker.endPos}ï¼Œæ–°çº¿ç¨‹ï¼š{_}ï¼Œæ–°çº¿ç¨‹çš„StartPosï¼š{s_pos}")

        else:
            logger.info(
                f"Task{self.fileName} æ¬²åˆ†é…æ–°çº¿ç¨‹å¤±è´¥, å‰©ä½™é‡å°äºæœ€å°åˆ†å—å¤§å°, å‰©ä½™é‡ï¼š{getReadableSize(maxRemainder)}")
    
    def clacDivisionalRange(self):
        '''é¢„å…ˆåˆ†å—'''
        step = self.fileSize // self.maxBlockNum  # æ¯å—å¤§å°
        arr = list(range(0, self.fileSize, step))

        # å¦åˆ™çº¿ç¨‹æ•°å¯èƒ½ä¼šä¸æŒ‰é¢„æœŸåœ°å°‘ä¸€ä¸ª
        if self.fileSize % self.maxBlockNum == 0:
            arr.append(self.fileSize)

        step_list = []

        for i in range(len(arr) - 1):  #

            s_pos, e_pos = arr[i], arr[i + 1] - 1
            step_list.append([s_pos, e_pos])

        step_list[-1][-1] = self.fileSize - 1  # ä¿®æ­£

        return step_list


    @retry(3, 0.1)
    def run(self):
        try:
            asyncio.run(self.main())
        except asyncio.exceptions.CancelledError:
            logger.info('ä»»åŠ¡è¢«å–æ¶ˆ/æš‚åœ')
        

    async def main(self):
        self.task = asyncio.current_task()
        try:
            # åˆå§‹åŒ–ä¿¡æ¯
            # è·å–çœŸå®URL
            self.url = getRealUrl(self.url)

            head = httpx.head(self.url, headers=Headers, proxy=getProxy()).headers

        except Exception as e: # é‡è¯•ä¹Ÿæ²¡ç”¨

            self.gotWrong.emit(str(e))

        # è·å–æ–‡ä»¶å¤§å°, åˆ¤æ–­æ˜¯å¦å¯ä»¥åˆ†å—ä¸‹è½½
        if "content-length" not in head:
            self.fileSize = 1
            self.ableToParallelDownload = False
        else:
            self.fileSize = int(head["content-length"])
            self.ableToParallelDownload = True

        # è·å–æ–‡ä»¶å
        if not self.fileName:
            try:
                # é¦–å…ˆï¼Œå°è¯•å¤„ç† Content-Disposition ä¸­çš„ self.fileName* (RFC 5987 æ ¼å¼)
                headerValue = head["content-disposition"]
                if 'fileName*' in headerValue:
                    match = re.search(r'filename\*\s*=\s*([^;]+)', headerValue, re.IGNORECASE)
                    if match:
                        self.fileName = match.group(1)
                        self.fileName = decode_rfc2231(self.fileName)
                        self.fileName = urllib.parse.unquote(self.fileName[2])  # self.fileName* åçš„éƒ¨åˆ†æ˜¯ç¼–ç ä¿¡æ¯

                # å¦‚æœ self.fileName* æ²¡æœ‰æˆåŠŸè·å–ï¼Œå°è¯•å¤„ç†æ™®é€šçš„ self.fileName
                if not self.fileName and 'filename' in headerValue:
                    match = re.search(r'filename\s*=\s*["\']?([^"\';]+)["\']?', headerValue, re.IGNORECASE)
                    if match:
                        self.fileName = match.group(1)

                # ç§»é™¤æ–‡ä»¶åå¤´å°¾å¯èƒ½å­˜åœ¨çš„å¼•å·
                if self.fileName:
                    self.fileName = self.fileName.strip('"\'')
                else:
                    raise KeyError

                logger.debug(f"æ–¹æ³•1è·å–æ–‡ä»¶åæˆåŠŸ, æ–‡ä»¶å:{self.fileName}")
            except (KeyError, IndexError) as e:
                try:
                    logger.info(f"æ–¹æ³•1è·å–æ–‡ä»¶åå¤±è´¥, KeyError or IndexError:{e}")
                    # è§£æ URL
                    # è§£ææŸ¥è¯¢å­—ç¬¦ä¸²
                    # è·å– response-content-disposition å‚æ•°
                    # è§£ç å¹¶åˆ†å‰² disposition
                    # æå–æ–‡ä»¶å
                    self.fileName = unquote(parse_qs(urlparse(self.url).query).get('response-content-disposition', [''])[0]).split("filename=")[-1]
                    # å»æ‰å¯èƒ½å­˜åœ¨çš„å¼•å·
                    if self.fileName.startswith('"') and self.fileName.endswith('"'):
                        self.fileName = self.fileName[1:-1]
                    elif self.fileName.startswith("'") and self.fileName.endswith("'"):
                        self.fileName = self.fileName[1:-1]

                    if not self.fileName:
                        raise KeyError

                    logger.debug(f"æ–¹æ³•2è·å–æ–‡ä»¶åæˆåŠŸ, æ–‡ä»¶å:{self.fileName}")

                except (KeyError, IndexError) as e:
                    # å¤„ç†æ²¡æœ‰æ–‡ä»¶åçš„æƒ…å†µ
                    logger.info(f"æ–¹æ³•2è·å–æ–‡ä»¶åå¤±è´¥, KeyError or IndexError:{e}")
                    self.fileName = urlparse(self.url).path.split('/')[-1]
                    logger.debug(f"æ–¹æ³•3è·å–æ–‡ä»¶åæˆåŠŸ, æ–‡ä»¶å:{self.fileName}")
            except Exception as e:
                # ä»€ä¹ˆéƒ½ Get ä¸åˆ°çš„æƒ…å†µ
                logger.info(f"è·å–æ–‡ä»¶åå¤±è´¥, Exception:{e}")
                content_type = head["content-type"].split('/')[-1]
                self.fileName = f"downloaded_file{int(time())}.{content_type}"
                logger.debug(f"æ–¹æ³•4è·å–æ–‡ä»¶åæˆåŠŸ, æ–‡ä»¶å:{self.fileName}")

        # è·å–æ–‡ä»¶è·¯å¾„
        if not self.filePath and Path(self.filePath).is_dir() == False:
            self.filePath = Path.cwd()
        else:
            self.filePath = Path(self.filePath)
            if not self.filePath.exists():
                self.filePath.mkdir()

        self.taskInited.emit()
        
        # TODO å‘æ¶ˆæ¯ç»™ä¸»çº¿ç¨‹
        if not self.ableToParallelDownload:
            self.maxBlockNum = 1
        # è¯»å–å†å²è®°å½•
        # å†å²è®°å½•.ghdæ–‡ä»¶é‡‡ç”¨æ ¼å¼ç¤ºä¾‹: ["start": 0, "process": 0, "end": 100, }, {"start": 101, "process": 111, "end": 200}]
        async with self.file_manager as self.file:

            if Path(f"{self.filePath}/{self.fileName}.ghd").exists():
                try:
                    with open(f"{self.filePath}/{self.fileName}.ghd", "r", encoding="utf-8") as f:
                        workersInfo = eval(f.read())
                        logger.debug(f"Task:{self.fileName}, history info is: {workersInfo}")
                        for i in workersInfo:
                            self.workers.append(
                                DownloadWorker(i["start"], i["process"], i["end"], self))

                    #self.refreshLastProgress.emit(str(sum([i.process - i.startPos for i in self.workers])))  # è¦ä¸ç„¶é€Ÿåº¦ä¼šé”™
                # TODO é”™è¯¯å¤„ç†
                except:
                    stepList = self.clacDivisionalRange()
                    for i in range(self.maxBlockNum):
                        self.workers.append(
                            DownloadWorker(stepList[i][0], stepList[i][0], stepList[i][1], self))
            else:
                stepList = self.clacDivisionalRange()
                for i in range(self.maxBlockNum):
                    self.workers.append(
                        DownloadWorker(stepList[i][0], stepList[i][0], stepList[i][1], self))

            for i in self.workers:
                #logger.debug(f"Task {self.fileName}, starting the thread {i}...")
                asyncio.create_task(i.run())

            # fileResolve = Path(f"{self.filePath}/{self.fileName}")
            # å®æ—¶ç»Ÿè®¡è¿›åº¦å¹¶å†™å…¥å†å²è®°å½•æ–‡ä»¶
            self.process = sum([i.process - i.startPos + 1 for i in self.workers])
            while not self.process == self.fileSize:
                with open(f"{self.filePath}/{self.fileName}.ghd", "w", encoding="utf-8") as f:
                    info = [{"start": i.startPos, "process": i.process, "end": i.endPos} for i in self.workers]
                    f.write(str(info))
                    f.flush()

                    # self.process = os.path.getsize(fileResolve)
                    # self.process = sum([i.process - i.startProcess + 1 for i in self.workers])
                    # self.processChange.emit(str(self.process))


                    self.workerInfoChange.emit(info)

                    # print(self.process, self.fileSize)

                    await asyncio.sleep(1)
            info = [{"start": i.startPos, "process": i.process, "end": i.endPos} for i in self.workers]#å®Œæˆåé¢å¤–åˆ·æ–°ä¸€æ¬¡
            #ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ,ä¸åŠ ä¼šæŠ¥é”™
            for i in self.workers:
                await i.task
            await self.file.close()
            

        # åˆ é™¤å†å²è®°å½•æ–‡ä»¶
        try:
            Path(f"{self.filePath}/{self.fileName}.ghd").unlink()

        except Exception as e:
            logger.error(f"Failed to delete the history file, please delete it manually. Err: {e}")

        logger.info(f"Task {self.fileName} finished!")
        self.workerInfoChange.emit(info)
        self.taskFinished.emit()


class DownloadWorker:
    """åªèƒ½å‡ºå–åŠ³åŠ¨åŠ›çš„æœ€åº•å±‚å·¥ä½œè€…"""


    def __init__(self, start, process, end, mission:DownloadTask):
        self.startPos = start
        self.process = process
        self.endPos = end
        self.mission = mission

    async def run(self):
        mission = self.mission
        self.task = asyncio.current_task()
        if self.process < self.endPos:  # å› ä¸ºå¯èƒ½ä¼šåˆ›å»ºç©ºçº¿ç¨‹
            finished = False
            while not finished:
                try:
                    if mission.ableToParallelDownload:
                        download_headers = {"Range": f"bytes={self.process}-{mission.fileSize}",
                                        "User-Agent": Headers["User-Agent"]}
                    else:
                        download_headers = {"User-Agent": Headers["User-Agent"]}

                    async with mission.client.stream(url=mission.url, headers=download_headers, timeout=30, method="GET") as res:
                        async for chunk in res.aiter_raw(chunk_size=65536):  # iter_content çš„å•ä½æ˜¯å­—èŠ‚, å³æ¯64Kå†™ä¸€æ¬¡æ–‡ä»¶
                            if self.process + 65536 < self.endPos:
                                async with mission.file_lock:
                                    await mission.file.seek(self.process)
                                    await mission.file.write(chunk)
                                self.process += 65536
                                mission.process += 65536
                            else:
                                chunk = chunk[: self.endPos - self.process]
                                len_chunk = self.endPos - self.process
                                async with mission.file_lock:
                                    await mission.file.seek(self.process)
                                    await mission.file.write(chunk)
                                    if (i := mission.workers.index(self) + 1) != len(mission.workers) and mission.workers[i].process > self.process + len_chunk:
                                        i = await mission.file.read(self.process + len_chunk - self.endPos)#
                                        if i != chunk[self.endPos - self.process:]:
                                            logger.error('æ ¡éªŒå¤±è´¥')
                                        else:
                                            logger.info(f'{self.startPos}æ ¡éªŒæˆåŠŸ')
                                    else:
                                        logger.debug('è·³è¿‡æ ¡éªŒ')
                                mission.process += len_chunk
                                self.process = self.endPos
                                finished = True
                                break

                except Exception as e:
                    logger.info(f"Task: {mission.fileName}, Thread {self} is reconnecting to the server, Error: {e}")

                    await asyncio.sleep(5)

            self.process = self.endPos
            mission.reassignWorker()
