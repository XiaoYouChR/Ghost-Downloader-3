import asyncio
import re
import struct
import urllib
from email.utils import decode_rfc2231
from pathlib import Path
from threading import Thread
from time import time
from types import coroutine
from urllib.parse import urlparse, parse_qs, unquote

import httpx
from PySide6.QtCore import QThread, Signal
from loguru import logger

from app.common.config import cfg
from app.common.methods import getProxy, getReadableSize

Headers = {
    "accept-encoding": "gzip, deflate, br",
    "accept-language": "zh-CN,zh;q=0.9",
    "cache-control": "max-age=0",
    "cookie": "down_ip=1",
    "sec-fetch-dest": "document",
    "sec-fetch-mode": "navigate",
    "sec-fetch-site": "none",
    "sec-fetch-user": "?1",
    "upgrade-insecure-requests": "1",
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 Edg/112.0.1722.64"}

urlRe = re.compile(r"^" +
                   "((?:https?|ftp)://)" +
                   "(?:\\S+(?::\\S*)?@)?" +
                   "(?:" +
                   "(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])" +
                   "(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}" +
                   "(\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))" +
                   "|" +
                   "((?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)" +
                   '(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)*' +
                   "(\\.([a-z\\u00a1-\\uffff]{2,}))" +
                   ")" +
                   "(?::\\d{2,5})?" +
                   "(?:/\\S*)?" +
                   "$", re.IGNORECASE)


# def getRealUrl(url: str):
#     response = httpx.head(url=url, headers=Headers, follow_redirects=False, verify=False,
#                           proxy=getProxy())
#
#     if response.status_code == 400:  # Bad Requests
#         # TODO æŠ¥é”™å¤„ç†
#         logger.error("HTTP status code 400, it seems that the url is unavailable")
#         return
#
#     while response.status_code == 302:  # å½“302çš„æ—¶å€™
#         rs = response.headers["location"]  # è·å–é‡å®šå‘ä¿¡æ¯
#         logger.info(f'HTTP status code:302, Headers["Location"] is: {rs}')
#         # çœ‹å®ƒè¿”å›çš„æ˜¯ä¸æ˜¯å®Œæ•´çš„URL
#         t = urlRe.search(rs)
#         if t:  # æ˜¯çš„è¯ç›´æ¥è·³è½¬
#             url = rs
#         elif not t:  # ä¸æ˜¯åœ¨å‰é¢åŠ ä¸ŠURL
#             url = re.findall(r"((?:https?|ftp)://[\s\S]*?)/", url)
#             url = url[0] + rs
#
#             logger.info(f"HTTP status code:302, Redirect to {url}")
#
#         response = httpx.head(url=url, headers=Headers, follow_redirects=False, verify=False,
#                               proxy=getProxy())  # å†è®¿é—®ä¸€æ¬¡
#
#     return url
class DownloadWorker:
    """åªèƒ½å‡ºå–åŠ³åŠ¨åŠ›çš„æœ€åº•å±‚å·¥ä½œè€…"""

    def __init__(self, start, process, end, client: httpx.AsyncClient):
        self.startPos = start
        self.process = process
        self.endPos = end

        self.client = client


class DownloadTask(QThread):
    """TaskManager"""

    taskInited = Signal()  # çº¿ç¨‹åˆå§‹åŒ–æˆåŠŸ
    # processChange = Signal(str)  # ç›®å‰è¿›åº¦ ä¸”å› ä¸ºC++ intæœ€å¤§å€¼ä»…æ”¯æŒåˆ°2^31 PyQtåˆæ²¡æœ‰Qintç±» æ•…åªèƒ½ä½¿ç”¨strä»£æ›¿
    workerInfoChange = Signal(list)  # ç›®å‰è¿›åº¦ v3.2ç‰ˆæœ¬å¼•è¿›äº†åˆ†æ®µå¼è¿›åº¦æ¡
    taskFinished = Signal()  # å†…ç½®ä¿¡å·çš„ä¸å¥½ç”¨
    gotWrong = Signal(str)  # ğŸ˜­ æˆ‘å‡ºé—®é¢˜äº†

    def __init__(self, url, maxBlockNum: int = 8, filePath=None, fileName=None, parent=None):
        super().__init__(parent)

        self.process = 0
        self.url = url
        self.fileName = fileName
        self.filePath = filePath
        self.maxBlockNum = maxBlockNum
        self.workers: list[DownloadWorker] = []
        self.tasks: list[coroutine] = []

        self.client = httpx.AsyncClient(headers=Headers, verify=False,
                                        proxy=getProxy(), limits=httpx.Limits(max_connections=256))
        self.fileLock = asyncio.Lock()

        self.__tempThread = Thread(target=self.__getLinkInfo, daemon=True)  # TODO è·å–æ–‡ä»¶åå’Œæ–‡ä»¶å¤§å°çš„çº¿ç¨‹ç­‰ä¿¡æ¯, æš‚æ—¶ä½¿ç”¨çº¿ç¨‹æ–¹å¼
        self.__tempThread.start()

    def __reassignWorker(self, task: coroutine):

        # æ‰¾åˆ°å‰©ä½™è¿›åº¦æœ€å¤šçš„çº¿ç¨‹
        maxRemainder = 0
        maxRemainderWorkerProcess = 0
        maxRemainderWorkerEnd = 0
        maxRemainderWorker: DownloadWorker = None

        for i in self.workers:
            if (i.endPos - i.process) > maxRemainder:  # TODO å…¶å®é€»è¾‘æœ‰ä¸€ç‚¹é—®é¢˜, ä½†æ˜¯å½±å“ä¸å¤§
                maxRemainderWorkerProcess = i.process
                maxRemainderWorkerEnd = i.endPos
                maxRemainder = (maxRemainderWorkerEnd - maxRemainderWorkerProcess)
                maxRemainderWorker = i

        if maxRemainderWorker and maxRemainder > cfg.maxReassignSize.value * 1048576:  # è½¬æ¢æˆ MB
            # å¹³å‡åˆ†é…å·¥ä½œé‡
            baseShare = maxRemainder // 2
            remainder = maxRemainder % 2

            maxRemainderWorker.endPos = maxRemainderWorkerProcess + baseShare + remainder  # ç›´æ¥ä¿®æ”¹å¥½åƒä¹Ÿä¸ä¼šæ€ä¹ˆæ ·

            # å®‰é…æ–°çš„å·¥äºº
            s_pos = maxRemainderWorkerProcess + baseShare + remainder + 1

            newWorker = DownloadWorker(s_pos, s_pos, maxRemainderWorkerEnd, self.client)

            loop = asyncio.get_event_loop()
            newTask = loop.create_task(self.__handleWorker(newWorker))
            newTask.add_done_callback(self.__reassignWorker)

            self.workers.insert(self.workers.index(maxRemainderWorker) + 1, newWorker)
            self.tasks.append(newTask)

            logger.info(
                f"Task{self.fileName} åˆ†é…æ–°çº¿ç¨‹æˆåŠŸ, å‰©ä½™é‡ï¼š{getReadableSize(maxRemainder)}ï¼Œä¿®æ”¹åçš„EndPosï¼š{maxRemainderWorker.endPos}ï¼Œæ–°çº¿ç¨‹ï¼š{newWorker}ï¼Œæ–°çº¿ç¨‹çš„StartPosï¼š{s_pos}")

        else:
            logger.info(
                f"Task{self.fileName} æ¬²åˆ†é…æ–°çº¿ç¨‹å¤±è´¥, å‰©ä½™é‡å°äºæœ€å°åˆ†å—å¤§å°, å‰©ä½™é‡ï¼š{getReadableSize(maxRemainder)}")

    def __clacDivisionalRange(self):
        step = self.fileSize // self.maxBlockNum  # æ¯å—å¤§å°
        arr = list(range(0, self.fileSize, step))

        # å¦åˆ™çº¿ç¨‹æ•°å¯èƒ½ä¼šä¸æŒ‰é¢„æœŸåœ°å°‘ä¸€ä¸ª
        if self.fileSize % self.maxBlockNum == 0:
            arr.append(self.fileSize)

        step_list = []

        for i in range(len(arr) - 1):  #

            s_pos, e_pos = arr[i], arr[i + 1] - 1
            step_list.append([s_pos, e_pos])

        step_list[-1][-1] = self.fileSize - 1  # ä¿®æ­£

        return step_list

    def __getLinkInfo(self):
        try:
            response = httpx.head(self.url, headers=Headers, verify=False, proxy=getProxy(), follow_redirects=True)
            response.raise_for_status()  # å¦‚æœçŠ¶æ€ç ä¸æ˜¯ 2xxï¼ŒæŠ›å‡ºå¼‚å¸¸

            head = response.headers

            self.url = str(response.url)

            # è·å–æ–‡ä»¶å¤§å°, åˆ¤æ–­æ˜¯å¦å¯ä»¥åˆ†å—ä¸‹è½½
            if "content-length" not in head:
                self.fileSize = 1
                self.ableToParallelDownload = False
            else:
                self.fileSize = int(head["content-length"])
                self.ableToParallelDownload = True

            # è·å–æ–‡ä»¶å
            if not self.fileName:
                try:
                    # å°è¯•å¤„ç† Content-Disposition ä¸­çš„ self.fileName* (RFC 5987 æ ¼å¼)
                    headerValue = head["content-disposition"]
                    if 'fileName*' in headerValue:
                        match = re.search(r'filename\*\s*=\s*([^;]+)', headerValue, re.IGNORECASE)
                        if match:
                            self.fileName = match.group(1)
                            self.fileName = decode_rfc2231(self.fileName)
                            self.fileName = urllib.parse.unquote(self.fileName[2])  # self.fileName* åçš„éƒ¨åˆ†æ˜¯ç¼–ç ä¿¡æ¯

                    # å¦‚æœ self.fileName* æ²¡æœ‰æˆåŠŸè·å–ï¼Œå°è¯•å¤„ç†æ™®é€šçš„ self.fileName
                    if not self.fileName and 'filename' in headerValue:
                        match = re.search(r'filename\s*=\s*["\']?([^"\';]+)["\']?', headerValue, re.IGNORECASE)
                        if match:
                            self.fileName = match.group(1)

                    # ç§»é™¤æ–‡ä»¶åå¤´å°¾å¯èƒ½å­˜åœ¨çš„å¼•å·
                    if self.fileName:
                        self.fileName = self.fileName.strip('"\'')
                    else:
                        raise KeyError

                    logger.debug(f"æ–¹æ³•1è·å–æ–‡ä»¶åæˆåŠŸ, æ–‡ä»¶å:{self.fileName}")
                except (KeyError, IndexError) as e:
                    try:
                        logger.info(f"æ–¹æ³•1è·å–æ–‡ä»¶åå¤±è´¥, KeyError or IndexError:{e}")
                        # è§£æ URL
                        # è§£ææŸ¥è¯¢å­—ç¬¦ä¸²
                        # è·å– response-content-disposition å‚æ•°
                        # è§£ç å¹¶åˆ†å‰² disposition
                        # æå–æ–‡ä»¶å
                        self.fileName = \
                        unquote(parse_qs(urlparse(self.url).query).get('response-content-disposition', [''])[0]).split(
                            "filename=")[-1]
                        # å»æ‰å¯èƒ½å­˜åœ¨çš„å¼•å·
                        if self.fileName.startswith('"') and self.fileName.endswith('"'):
                            self.fileName = self.fileName[1:-1]
                        elif self.fileName.startswith("'") and self.fileName.endswith("'"):
                            self.fileName = self.fileName[1:-1]

                        if not self.fileName:
                            raise KeyError

                        logger.debug(f"æ–¹æ³•2è·å–æ–‡ä»¶åæˆåŠŸ, æ–‡ä»¶å:{self.fileName}")

                    except (KeyError, IndexError) as e:

                        logger.info(f"æ–¹æ³•2è·å–æ–‡ä»¶åå¤±è´¥, KeyError or IndexError:{e}")
                        self.fileName = urlparse(self.url).path.split('/')[-1]

                        if self.fileName:
                            logger.debug(f"æ–¹æ³•3è·å–æ–‡ä»¶åæˆåŠŸ, æ–‡ä»¶å:{self.fileName}")
                        else:
                            logger.debug("æ–¹æ³•3è·å–æ–‡ä»¶åå¤±è´¥, æ–‡ä»¶åä¸ºç©º")
                            # ä»€ä¹ˆéƒ½ Get ä¸åˆ°çš„æƒ…å†µ
                            logger.info(f"è·å–æ–‡ä»¶åå¤±è´¥, é”™è¯¯:{e}")
                            content_type = head["content-type"].split('/')[-1]
                            self.fileName = f"downloaded_file{int(time())}.{content_type}"
                            logger.debug(f"æ–¹æ³•4è·å–æ–‡ä»¶åæˆåŠŸ, æ–‡ä»¶å:{self.fileName}")

            # è·å–æ–‡ä»¶è·¯å¾„
            if not self.filePath and Path(self.filePath).is_dir() == False:
                self.filePath = Path.cwd()

            else:
                self.filePath = Path(self.filePath)
                if not self.filePath.exists():
                    self.filePath.mkdir()

            self.taskInited.emit()

        except Exception as e:  # é‡è¯•ä¹Ÿæ²¡ç”¨
            self.gotWrong.emit(str(e))

    def __loadWorkers(self):
        # å¦‚æœ .ghd æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å¹¶è§£æäºŒè¿›åˆ¶æ•°æ®
        filePath = Path(f"{self.filePath}/{self.fileName}.ghd")
        if filePath.exists():
            try:
                with open(filePath, "rb") as f:
                    while True:
                        data = f.read(24)  # æ¯ä¸ª worker æœ‰ 3 ä¸ª 64 ä½çš„æ— ç¬¦å·æ•´æ•°ï¼Œå…± 24 å­—èŠ‚

                        if not data:
                            break

                        start, process, end = struct.unpack("<QQQ", data)
                        self.workers.append(
                            DownloadWorker(start, process, end, self.client))

            except Exception as e:
                logger.error(f"Failed to load workers: {e}")
                stepList = self.__clacDivisionalRange()

                for i in range(self.maxBlockNum):
                    self.workers.append(
                        DownloadWorker(stepList[i][0], stepList[i][0], stepList[i][1], self.client))
        else:
            stepList = self.__clacDivisionalRange()

            for i in range(self.maxBlockNum):
                self.workers.append(
                    DownloadWorker(stepList[i][0], stepList[i][0], stepList[i][1], self.client))

    async def __handleWorker(self, worker: DownloadWorker):
        if worker.process < worker.endPos:  # å› ä¸ºå¯èƒ½ä¼šåˆ›å»ºç©ºçº¿ç¨‹
            finished = False
            while not finished:
                try:
                    download_headers = Headers
                    download_headers["range"] = f"bytes={worker.process}-{worker.endPos}"  # æ·»åŠ èŒƒå›´

                    async with worker.client.stream(url=self.url, headers=download_headers, timeout=30,
                                                    method="GET") as res:
                        async for chunk in res.aiter_raw(chunk_size=65536):  # aiter_content çš„å•ä½æ˜¯å­—èŠ‚, å³æ¯64Kå†™ä¸€æ¬¡æ–‡ä»¶
                            if worker.endPos <= worker.process:
                                break
                            if chunk:
                                async with self.fileLock:  # å¿…é¡»åŠ é”ï¼
                                    self.file.seek(worker.process)
                                    self.file.write(chunk)
                                    worker.process += 65536

                    if worker.process >= worker.endPos:
                        worker.process = worker.endPos

                    finished = True

                except Exception as e:
                    logger.info(
                        f"Task: {self.fileName}, Thread {worker} is reconnecting to the server, Error: {repr(e)}")

                    self.gotWrong.emit(repr(e))

                    await asyncio.sleep(5)

            worker.process = worker.endPos

    async def __supervisor(self):
        """å®æ—¶ç»Ÿè®¡è¿›åº¦å¹¶å†™å…¥å†å²è®°å½•æ–‡ä»¶"""

        while not self.process == self.fileSize:

            self.ghdFile.seek(0)
            info = []
            self.process = 0

            for i in self.workers:
                info.append({"start": i.startPos, "process": i.process, "end": i.endPos})

                self.process += (i.process - i.startPos + 1)

                # ä¿å­˜ workers ä¿¡æ¯ä¸ºäºŒè¿›åˆ¶æ ¼å¼
                data = struct.pack("<QQQ", i.startPos, i.process, i.endPos)
                self.ghdFile.write(data)

            self.ghdFile.flush()
            self.ghdFile.truncate()

            self.workerInfoChange.emit(info)

            await asyncio.sleep(1)

    async def __main(self):
        try:
            # æ‰“å¼€ä¸‹è½½æ–‡ä»¶
            self.file = open(f"{self.filePath}/{self.fileName}", "rb+")

            # å¯åŠ¨ Worker
            for i in self.workers:
                logger.debug(f"Task {self.fileName}, starting the thread {i}...")

                _ = asyncio.create_task(self.__handleWorker(i))
                _.add_done_callback(self.__reassignWorker)

                self.tasks.append(_)

            self.ghdFile = open(f"{self.filePath}/{self.fileName}.ghd", "wb")
            supervisorTask = asyncio.create_task(self.__supervisor())

            # ä»…ä»…éœ€è¦ç­‰å¾… supervisorTask
            await supervisorTask

            # å…³é—­
            await self.client.aclose()

        except Exception as e:
            self.gotWrong.emit(repr(e))

    # @retry(3, 0.1)
    def run(self):
        self.__tempThread.join()

        # åˆ›å»ºç©ºæ–‡ä»¶
        Path(f"{self.filePath}/{self.fileName}").touch()

        # TODO å‘æ¶ˆæ¯ç»™ä¸»çº¿ç¨‹
        if not self.ableToParallelDownload:
            self.maxBlockNum = 1

        # åŠ è½½åˆ†å—
        self.__loadWorkers()

        # ä¸»é€»è¾‘, ä½¿ç”¨äº‹ä»¶å¾ªç¯å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            loop.run_until_complete(self.__main())
        except asyncio.CancelledError:
            pass
        finally:
            loop.run_until_complete(loop.shutdown_asyncgens())
            loop.close()

        self.file.close()
        self.ghdFile.close()

        # åˆ é™¤å†å²è®°å½•æ–‡ä»¶
        try:
            Path(f"{self.filePath}/{self.fileName}.ghd").unlink()

        except Exception as e:
            logger.error(f"Failed to delete the history file, please delete it manually. Err: {e}")

        logger.info(f"Task {self.fileName} finished!")

        self.taskFinished.emit()
