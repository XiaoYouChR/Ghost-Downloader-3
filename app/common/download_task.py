import asyncio
import struct
import sys
import time
from pathlib import Path
from threading import Thread

import curl_cffi
from PySide6.QtCore import QThread, Signal
from loguru import logger

from app.common.config import cfg
from app.common.methods import getProxy, getReadableSize, getLinkInfo, createSparseFile


class DownloadWorker:
    """åªèƒ½å‡ºå–åŠ³åŠ¨åŠ›çš„æœ€åº•å±‚å·¥ä½œè€…"""

    def __init__(self, start, progress, end):
        self.startPos = start
        self.progress = progress
        self.endPos = end


class MutiThreadContext:
    """å¤šçº¿ç¨‹å¥æŸ„ï¼Œå¦‚æœDownloadTaskçš„æ–¹æ³•éœ€è¦ä½¿ç”¨å¤šçº¿ç¨‹ï¼Œåˆ™éœ€è¦å°†è¯¥ç±»ä½œä¸ºå‚æ•°ä¼ å…¥"""

    def __init__(self, fileSize):
        self.workers: list[DownloadWorker] = []
        self.taskgroup = asyncio.TaskGroup()
        self.running_task_count: int = 0
        self.fileSize: int = fileSize
        self.done: bool = False


class DownloadTask(QThread):
    """Task Manager
    self.fileSize == -1 è¡¨ç¤ºè‡ªåŠ¨è·å–; == 0 è¡¨ç¤ºä¸èƒ½å¹¶è¡Œä¸‹è½½; else è¡¨ç¤ºæ­£å¸¸"""

    taskInited = Signal(bool)  # çº¿ç¨‹åˆå§‹åŒ–æˆåŠŸ, å¹¶ä¼ é€’æ˜¯å¦æ”¯æŒå¹¶è¡Œä¸‹è½½çš„ä¿¡æ¯
    # processChange = Signal(str)  # ç›®å‰è¿›åº¦ ä¸”å› ä¸ºC++ intæœ€å¤§å€¼ä»…æ”¯æŒåˆ°2^31 PyQtåˆæ²¡æœ‰Qintç±» æ•…åªèƒ½ä½¿ç”¨strä»£æ›¿
    workerInfoChanged = Signal(list)  # ç›®å‰è¿›åº¦ v3.2ç‰ˆæœ¬å¼•è¿›äº†åˆ†æ®µå¼è¿›åº¦æ¡
    speedChanged = Signal(
        int
    )  # å¹³å‡é€Ÿåº¦ å› ä¸º autoSpeedUp åŠŸèƒ½éœ€è¦å®æ—¶è®¡ç®—å¹³å‡é€Ÿåº¦ v3.4.4 èµ·ç§»å…¥åç«¯è®¡ç®—é€Ÿåº¦, æ¯ç§’é€Ÿåº¦å¯èƒ½è¶…è¿‡ 2^31 Bytes å—ï¼Ÿ
    taskFinished = Signal()  # å†…ç½®ä¿¡å·çš„ä¸å¥½ç”¨
    gotWrong = Signal(str)  # ğŸ˜­ æˆ‘å‡ºé—®é¢˜äº†

    def __init__(
        self,
        url,
        headers,
        preTaskNum: int = 8,
        filePath: str = None,
        fileName: str = None,
        autoSpeedUp: bool = False,
        fileSize: int = -1,
        parent=None,
    ):
        super().__init__(parent)

        self.progress = 0
        self.url = url
        self.headers = headers
        self.fileName = fileName
        self.filePath = filePath
        self.preBlockNum = preTaskNum
        self.autoSpeedUp = autoSpeedUp
        self.fileSize = fileSize
        self.ableToParallelDownload: bool

        self.historySpeed = [0] * 10  # å†å²é€Ÿåº¦ 10 ç§’å†…çš„å¹³å‡é€Ÿåº¦

        proxy = getProxy()

        self.client = curl_cffi.AsyncSession(
            headers=headers,
            verify=cfg.SSLVerify.value,
            proxy=proxy,
            max_clients=256,
            trust_env=False,
            allow_redirects=True,
            impersonate="chrome",
            http_version="v3",
        )

        self.__initThread = Thread(
            target=self.__initTask, daemon=True
        )  # TODO è·å–æ–‡ä»¶åå’Œæ–‡ä»¶å¤§å°çš„çº¿ç¨‹ç­‰ä¿¡æ¯, æš‚æ—¶ä½¿ç”¨çº¿ç¨‹æ–¹å¼
        self.__initThread.start()

    def __reassignWorker(self, context: MutiThreadContext):

        # æ‰¾åˆ°å‰©ä½™è¿›åº¦æœ€å¤šçš„çº¿ç¨‹
        maxRemainder = 0
        maxRemainderWorkerProcess = 0
        maxRemainderWorkerEnd = 0
        maxRemainderWorker: DownloadWorker = None

        for i in context.workers:
            if (
                i.endPos - i.progress
            ) > maxRemainder:  # å…¶å®é€»è¾‘æœ‰ä¸€ç‚¹é—®é¢˜, ä½†æ˜¯å½±å“ä¸å¤§
                maxRemainderWorkerProcess = i.progress
                maxRemainderWorkerEnd = i.endPos
                maxRemainder = maxRemainderWorkerEnd - maxRemainderWorkerProcess
                maxRemainderWorker = i

        if (
            maxRemainderWorker and maxRemainder > cfg.maxReassignSize.value * 1048576
        ):  # è½¬æ¢æˆ MB
            # å¹³å‡åˆ†é…å·¥ä½œé‡
            baseShare = maxRemainder // 2
            remainder = maxRemainder % 2

            maxRemainderWorker.endPos = (
                maxRemainderWorkerProcess + baseShare + remainder
            )  # ç›´æ¥ä¿®æ”¹å¥½åƒä¹Ÿä¸ä¼šæ€ä¹ˆæ ·

            # å®‰é…æ–°çš„å·¥äºº
            startPos = (
                maxRemainderWorkerProcess + baseShare + remainder + 1
            )  # é™¤ä»¥2å‘ä¸Šå–æ•´

            newWorker = DownloadWorker(startPos, startPos, maxRemainderWorkerEnd)

            context.taskgroup.create_task(self.__handleWorker(newWorker, context))
            context.workers.insert(
                context.workers.index(maxRemainderWorker) + 1, newWorker
            )
            context.running_task_count += 1
            logger.info(
                f"Task{self.fileName} åˆ†é…æ–°çº¿ç¨‹æˆåŠŸ, å‰©ä½™é‡ï¼š{getReadableSize(maxRemainder)}ï¼Œä¿®æ”¹åçš„EndPosï¼š{maxRemainderWorker.endPos}ï¼Œæ–°çº¿ç¨‹ï¼š{newWorker}ï¼Œæ–°çº¿ç¨‹çš„StartPosï¼š{startPos}"
            )

        else:
            logger.info(
                f"Task{self.fileName} æ¬²åˆ†é…æ–°çº¿ç¨‹å¤±è´¥, å‰©ä½™é‡å°äºæœ€å°åˆ†å—å¤§å°, å‰©ä½™é‡ï¼š{getReadableSize(maxRemainder)}"
            )


    def __calcDivisionalRange(self, context: MutiThreadContext):
        step = context.fileSize // self.preBlockNum  # æ¯å—å¤§å°
        start = 0
        for i in range(self.preBlockNum - 1):
            end = start + step - 1
            yield DownloadWorker(start, start, end)
            start = end + 1

        yield DownloadWorker(start, start, context.fileSize - 1)


    def __initTask(self):
        """è·å–é“¾æ¥ä¿¡æ¯å¹¶åˆå§‹åŒ–çº¿ç¨‹"""
        try:
            if self.fileSize == -1 or not self.fileName:
                self.url, self.fileName, self.fileSize = getLinkInfo(
                    self.url, self.headers, self.fileName
                )

            if self.fileSize:
                self.ableToParallelDownload = True
            else:
                self.ableToParallelDownload = False  # å¤„ç†æ— æ³•å¹¶è¡Œä¸‹è½½çš„æƒ…å†µ

            # è·å–æ–‡ä»¶è·¯å¾„
            if not self.filePath and Path(self.filePath).is_dir() == False:
                self.filePath = Path.cwd()

            else:
                self.filePath = Path(self.filePath)
                if not self.filePath.exists():
                    self.filePath.mkdir()

            # æ£€éªŒæ–‡ä»¶åˆæ³•æ€§å¹¶è‡ªåŠ¨é‡å‘½å
            if sys.platform == "win32":
                self.fileName = "".join(
                    [i for i in self.fileName if i not in r'\/:*?"<>|']
                )  # å»é™¤Windowsç³»ç»Ÿä¸å…è®¸çš„å­—ç¬¦
            if len(self.fileName) > 255:
                self.fileName = self.fileName[:255]

            filePath = Path(f"{self.filePath}/{self.fileName}")

            if not filePath.exists():
                filePath.touch()
                try:
                    createSparseFile(filePath)
                except Exception as e:
                    logger.warning("åˆ›å»ºç¨€ç–æ–‡ä»¶å¤±è´¥", repr(e))

            # ä»»åŠ¡åˆå§‹åŒ–å®Œæˆ
            if self.ableToParallelDownload:
                self.taskInited.emit(True)
            else:
                self.taskInited.emit(False)
                self.preBlockNum = 1

        except Exception as e:  # é‡è¯•ä¹Ÿæ²¡ç”¨
            self.gotWrong.emit(repr(e))

    def __loadWorkers(self, context: MutiThreadContext):
        """å¯ç»­ä¼ çš„æƒ…å†µä¸‹è¯»å–å·²å­˜åœ¨çš„ .ghd æ–‡ä»¶"""
        # if not self.ableToParallelDownload:
        #     # å¦‚æœæ— æ³•å¹¶è¡Œä¸‹è½½ï¼Œåˆ›å»ºä¸€ä¸ªå•çº¿ç¨‹çš„ worker
        #     self.workers.append(DownloadWorker(0, 0, 1, self.client))
        #     return

        # å¦‚æœ .ghd æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å¹¶è§£æäºŒè¿›åˆ¶æ•°æ®
        filePath = Path(f"{self.filePath}/{self.fileName}.ghd")
        if filePath.exists():
            try:
                with open(filePath, "rb") as f:
                    while True:
                        data = f.read(
                            24
                        )  # æ¯ä¸ª worker æœ‰ 3 ä¸ª 64 ä½çš„æ— ç¬¦å·æ•´æ•°ï¼Œå…± 24 å­—èŠ‚

                        if not data:
                            break

                        start, process, end = struct.unpack("<QQQ", data)
                        context.workers.append(DownloadWorker(start, process, end))

            except Exception as e:
                logger.error(f"Failed to load workers: {e}")

                for worker in self.__calcDivisionalRange(context):
                    context.workers.append(worker)
        else:

            for worker in self.__calcDivisionalRange(context):
                context.workers.append(worker)
            

    # å¤šçº¿ç¨‹ä¸»ä¸‹è½½é€»è¾‘
    async def __handleWorker(self, worker: DownloadWorker, context: MutiThreadContext):
        logger.debug(
            f"{self.fileName} task is launching the worker {worker.startPos}-{worker.endPos}..."
        )
        if worker.progress < worker.endPos:  # å› ä¸ºå¯èƒ½ä¼šåˆ›å»ºç©ºçº¿ç¨‹
            finished = False
            while not finished:
                try:
                    workingRangeHeaders = self.headers.copy()

                    workingRangeHeaders["range"] = (
                        f"bytes={worker.progress}-{worker.endPos}"  # æ·»åŠ èŒƒå›´
                    )

                    res = await self.client.stream(
                        url=self.url,
                        headers=workingRangeHeaders,
                        timeout=30,
                        method="GET",
                    ).__aenter__()  # ç›´æ¥ä½¿ç”¨async withæš‚åœæ—¶ä¼šå¡ä½ï¼ŒåŸå› ä¸æ˜
                    try:
                        res: curl_cffi.Response
                        res.raise_for_status()
                        if res.status_code != 206:
                            raise Exception(
                                f"æœåŠ¡å™¨æ‹’ç»äº†èŒƒå›´è¯·æ±‚ï¼ŒçŠ¶æ€ç ï¼š{res.status_code}"
                            )
                        async for chunk in res.aiter_content():
                            if worker.endPos <= worker.progress:
                                break
                            if chunk:
                                self.file.seek(worker.progress)
                                self.file.write(chunk)
                                chunkSize = len(chunk)
                                worker.progress += chunkSize
                                cfg.globalSpeed += chunkSize
                                if cfg.speedLimitation.value:
                                    if cfg.globalSpeed >= cfg.speedLimitation.value:
                                        time.sleep(1)
                    finally:
                        # res: curl_cffi.Response
                        res.close()

                    if worker.progress >= worker.endPos:
                        worker.progress = worker.endPos

                    finished = True

                except Exception as e:
                    logger.info(
                        f"Task: {self.fileName}, Thread {worker} is reconnecting to the server, Error: {repr(e)}"
                    )

                    self.gotWrong.emit(repr(e))

                    await asyncio.sleep(5)

            worker.progress = worker.endPos

        if (
            not self.autoSpeedUp or context.running_task_count <= self.preBlockNum
        ):  # å¦‚æœå¼€å¯äº†è‡ªåŠ¨æé€Ÿä¸”æ·»åŠ äº†é¢å¤–çº¿ç¨‹ï¼Œåˆ™é‡æ–°åˆ†é…å·¥ä½œçº¿ç¨‹ç”±è‡ªåŠ¨æé€Ÿæ§åˆ¶
            self.__reassignWorker(context)
        context.running_task_count += 1

    async def __handleWorkerWhenUnableToParallelDownload(self):
        finished = False
        while not finished:
            # fix me: å•çº¿ç¨‹ä¸‹è½½ä»»åŠ¡åœ¨é‡è¿åè¿›åº¦ä¸æ­£ç¡®ï¼Œä½†ç›´æ¥å°†è¿›åº¦é‡ç½®ä¸º0åˆä¼šå¯¼è‡´é€Ÿåº¦å¼‚å¸¸
            # self.progress = 0
            try:
                self.file.seek(0)
                WorkingRangeHeaders = self.headers.copy()
                async with self.client.stream(
                    url=self.url,
                    headers=WorkingRangeHeaders,
                    timeout=30,
                    method="GET",
                ) as res:
                    res.raise_for_status()
                    async for chunk in res.aiter_content():
                        if chunk:
                            self.file.write(chunk)
                            _ = len(chunk)
                            self.progress += _
                            cfg.globalSpeed += _
                            if cfg.speedLimitation.value:
                                if cfg.globalSpeed >= cfg.speedLimitation.value:
                                    time.sleep(1)

                self.ableToParallelDownload = True  # äº‹å®ä¸Šç”¨æ¥è¡¨ç¤ºä»»åŠ¡å·²ç»å®Œæˆ

                finished = True

            except Exception as e:
                logger.info(
                    f"Task: {self.fileName}, Thread {self} is reconnecting to the server, Error: {repr(e)}"
                )

                self.gotWrong.emit(repr(e))

                await asyncio.sleep(5)

        # worker.progress = worker.endPos

    async def __supervisor(self, context: MutiThreadContext):
        """å®æ—¶ç»Ÿè®¡è¿›åº¦å¹¶å†™å…¥å†å²è®°å½•æ–‡ä»¶"""
        LastProgress = (
            0  # å¯èƒ½ä¼šå‡ºç°unbound errorï¼Œæ‰€ä»¥å°†LastProgressæå–ä¸ºå‡½æ•°å…¨å±€å˜é‡
        )

        for i in context.workers:
            self.progress += i.progress - i.startPos + 1
            LastProgress = self.progress

        if self.autoSpeedUp:
            # åˆå§‹åŒ–å˜é‡
            maxSpeedPerConnect = 1  # é˜²æ­¢é™¤ä»¥ 0
            additionalTaskNum = (
                context.running_task_count
            )  # æœ€åˆä¸ºè®¡ç®—æ¯ä¸ªçº¿ç¨‹çš„å¹³å‡é€Ÿåº¦
            formerAvgSpeed = 0.0  # æé€Ÿä¹‹å‰çš„å¹³å‡é€Ÿåº¦
            duringTime = 0  # è®¡ç®—å¹³å‡é€Ÿåº¦çš„æ—¶é—´é—´éš”, ä¸º 10 ç§’
            _ = 0
        ghdFile = open(f"{self.filePath}/{self.fileName}.ghd", "wb")
        try:
            while True:  # ç”±å¤–å±‚cancelé€€å‡º

                info = []
                # è®°å½•æ¯å—ä¿¡æ¯
                ghdFile.seek(0)
                self.progress = 0

                for i in context.workers:
                    info.append(
                        {"start": i.startPos, "progress": i.progress, "end": i.endPos}
                    )

                    self.progress += i.progress - i.startPos + 1

                    # ä¿å­˜ workers ä¿¡æ¯ä¸ºäºŒè¿›åˆ¶æ ¼å¼
                    data = struct.pack("<QQQ", i.startPos, i.progress, i.endPos)
                    ghdFile.write(data)

                ghdFile.flush()
                ghdFile.truncate()

                self.workerInfoChanged.emit(info)

                # è®¡ç®—é€Ÿåº¦
                speed = self.progress - LastProgress
                # print(f"speed: {speed}, progress: {self.progress}, LastProgress: {LastProgress}")
                LastProgress = self.progress
                self.historySpeed.pop(0)
                self.historySpeed.append(speed)
                avgSpeed = sum(self.historySpeed) / 10

                self.speedChanged.emit(avgSpeed)

                # print(f"avgSpeed: {avgSpeed}, historySpeed: {self.historySpeed}")

                if self.autoSpeedUp:
                    if duringTime < 10:
                        duringTime += 1
                    else:
                        duringTime = 0

                        speedPerConnect = avgSpeed / context.running_task_count
                        if speedPerConnect > maxSpeedPerConnect:
                            maxSpeedPerConnect = speedPerConnect
                            _ = (
                                0.9 * maxSpeedPerConnect * additionalTaskNum
                            ) + formerAvgSpeed
                        if avgSpeed >= _:
                            formerAvgSpeed = avgSpeed
                            additionalTaskNum = 4
                            _ = (
                                0.85 * maxSpeedPerConnect * additionalTaskNum
                            ) + formerAvgSpeed

                            if context.running_task_count < 253:
                                for i in range(4):
                                    self.__reassignWorker(context)  # æ–°å¢çº¿ç¨‹

                await asyncio.sleep(1)

        except Exception as e:
            logger.error(f"Supervisor error: {e}")
            self.gotWrong.emit(repr(e))

        finally:
            ghdFile.close()
            if context.done:
                try:
                    Path(f"{self.filePath}/{self.fileName}.ghd").unlink()
                except Exception as e:
                    logger.error(
                        f"Failed to delete the history file, please delete it manually. Err: {e}"
                    )

    async def __supervisorSingleThread(self):
        LastProgress = 0
        while True:

            self.workerInfoChanged.emit([])

            # è®¡ç®—é€Ÿåº¦
            speed = self.progress - LastProgress
            LastProgress = self.progress
            self.historySpeed.pop(0)
            self.historySpeed.append(speed)
            avgSpeed = sum(self.historySpeed) / 10

            self.speedChanged.emit(avgSpeed)

            await asyncio.sleep(1)

    async def __main(self):
        try:
            # æ‰“å¼€ä¸‹è½½æ–‡ä»¶
            self.file = open(f"{self.filePath}/{self.fileName}", "rb+")

            if self.ableToParallelDownload:
                # å¤šçº¿ç¨‹éƒ¨åˆ†
                # åŠ è½½åˆ†å—
                context = MutiThreadContext(self.fileSize)

                self.__loadWorkers(context)
                supervisorTask = asyncio.create_task(self.__supervisor(context))
                try:
                    async with context.taskgroup as tg:
                        for i in context.workers:  # å¯åŠ¨ Worker
                            tg.create_task(self.__handleWorker(i, context))
                            context.running_task_count += 1
                    context.done = True
                    logger.info(f"Task {self.fileName} finished!")
                    self.taskFinished.emit()

                finally:
                    supervisorTask.cancel()
                    await supervisorTask

            else:
                # å•çº¿ç¨‹éƒ¨åˆ†
                supervisor = asyncio.create_task(self.__supervisorSingleThread())
                try:
                    await self.__handleWorkerWhenUnableToParallelDownload()
                finally:
                    self.taskFinished.emit()
                    supervisor.cancel()
                    await supervisor

        except Exception as e:
            self.gotWrong.emit(repr(e))

        finally:  # å…³é—­
            await self.client.close()
            self.file.close()
            # if not self.fileSize:
            #     logger.info(f"Task {self.fileName} finished!")
            #     self.taskFinished.emit()

            # if self.progress == self.fileSize:
            #     logger.info(f"Task {self.fileName} finished!")
            #     self.taskFinished.emit()

    def stop(self):
        self._mainTask.cancel()

    # @retry(3, 0.1)
    def run(self):
        self.__initThread.join()

        # ä¸»é€»è¾‘, ä½¿ç”¨äº‹ä»¶å¾ªç¯å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)

        try:
            self._mainTask = self.loop.create_task(self.__main())
            self.loop.run_until_complete(self._mainTask)
        except asyncio.CancelledError as e:
            print(e)
        finally:
            self.loop.run_until_complete(self.loop.shutdown_asyncgens())
            self.loop.close()
